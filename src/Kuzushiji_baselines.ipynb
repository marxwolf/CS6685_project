{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a download option:\n",
      "1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)\n",
      "2) Kuzushiji-49 (49 classes, 28x28, 270k examples)\n",
      "3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a download option:\n",
      "1) MNIST data format (ubyte.gz)\n",
      "2) NumPy data format (.npz)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kmnist-train-imgs.npz - 18.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17954/17954 [00:09<00:00, 1880.36KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kmnist-train-labels.npz - 0.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 263.09KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kmnist-test-imgs.npz - 3.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3008/3008 [00:02<00:00, 1340.81KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading kmnist-test-labels.npz - 0.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?KB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dataset files downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x, total, unit: x  # If tqdm doesn't exist, replace it with a function that does nothing\n",
    "    print('**** Could not import tqdm. Please install tqdm for download progressbars! (pip install tqdm) ****')\n",
    "\n",
    "# Python2 compatibility\n",
    "try:\n",
    "    input = raw_input\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "download_dict = {\n",
    "    '1) Kuzushiji-MNIST (10 classes, 28x28, 70k examples)': {\n",
    "        '1) MNIST data format (ubyte.gz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'],\n",
    "        '2) NumPy data format (.npz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'],\n",
    "    },\n",
    "    '2) Kuzushiji-49 (49 classes, 28x28, 270k examples)': {\n",
    "        '1) NumPy data format (.npz)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-train-labels.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-imgs.npz',\n",
    "            'http://codh.rois.ac.jp/kmnist/dataset/k49/k49-test-labels.npz'],\n",
    "    },\n",
    "    '3) Kuzushiji-Kanji (3832 classes, 64x64, 140k examples)': {\n",
    "        '1) Folders of images (.tar)':\n",
    "            ['http://codh.rois.ac.jp/kmnist/dataset/kkanji/kkanji.tar'],\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "# Download a list of files\n",
    "def download_list(url_list):\n",
    "    for url in url_list:\n",
    "        path = url.split('/')[-1]\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(path, 'wb') as f:\n",
    "            total_length = int(r.headers.get('content-length'))\n",
    "            print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
    "\n",
    "            for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print('All dataset files downloaded!')\n",
    "\n",
    "# Ask the user about which path to take down the dict\n",
    "def traverse_dict(d):\n",
    "    print('Please select a download option:')\n",
    "    keys = sorted(d.keys())  # Print download options\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "\n",
    "    userinput = input('> ').strip()\n",
    "\n",
    "    try:\n",
    "        selection = int(userinput) - 1\n",
    "    except ValueError:\n",
    "        print('Your selection was not valid')\n",
    "        traverse_dict(d)  # Try again if input was not valid\n",
    "        return\n",
    "\n",
    "    selected = keys[selection]\n",
    "\n",
    "    next_level = d[selected]\n",
    "    if isinstance(next_level, list):  # If we've hit a list of downloads, download that list\n",
    "        download_list(next_level)\n",
    "    else:\n",
    "        traverse_dict(next_level)     # Otherwise, repeat with the next level\n",
    "\n",
    "traverse_dict(download_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the directory for input data and output pickles to save the model parameters\n",
    "#see comments for more detail on pickes in the last cell.. \n",
    "datadir='./'\n",
    "\n",
    "#dataset = 1 for KMNIST, 2 for K49\n",
    "dataset = 1\n",
    "\n",
    "#Dataset 2(K49) may take longer computation time than one day).\n",
    "#You may test with small dataset by setting the following variable to 'True'\n",
    "small_dataset = False\n",
    "\n",
    "#if the above parameter is set to be 'True', then only the following number of instances will be used for training.\n",
    "#number of training data in original dataset 1 and 2 is 60000 and 232365 respectively.\n",
    "number_of_instances_for_small_dataset = 1000 \n",
    "\n",
    "#multi-class decision function. While an 'ovr' option is fast. an'ovo' optionis very slow, but, it classifties better for unbalanced numbers of instances among classes.  \n",
    "decision_function_shape=\"ovr\"\n",
    "\n",
    "# Make sure that the following files are set in 'datadir' directory.\n",
    "\n",
    "if dataset == 1:\n",
    "    #Dataset 1 KMNNIST 10\n",
    "    filename_train_img   = \"kmnist-train-imgs\"\n",
    "    filename_train_label = \"kmnist-train-labels\"\n",
    "    filename_test_img    = \"kmnist-test-imgs\"\n",
    "    filename_test_label  = \"kmnist-test-labels\"\n",
    "    pickles_id = \"data1\"\n",
    "elif dataset == 2:\n",
    "    #Dataset 2 K49\n",
    "    filename_train_img   = \"k49-train-imgs\"\n",
    "    filename_train_label = \"k49-train-labels\"\n",
    "    filename_test_img    = \"k49-test-imgs\"\n",
    "    filename_test_label  = \"k49-test-labels\"\n",
    "    pickles_id = \"data2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "### Data Input\n",
    "################################\n",
    "\n",
    "X_train = np.load(datadir+filename_train_img+'.npz')['arr_0']\n",
    "y_train = np.load(datadir+filename_train_label+'.npz')['arr_0']\n",
    "X_test = np.load(datadir+filename_test_img+'.npz')['arr_0']\n",
    "y_test = np.load(datadir+filename_test_label+'.npz')['arr_0']\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train,(-1,28*28))\n",
    "X_test  = np.reshape(X_test, (-1,28*28))\n",
    "\n",
    "\n",
    "ntrain = len(X_train)\n",
    "ntest = len(X_test)\n",
    "\n",
    "np.random.seed(42)\n",
    "rnd_idx = np.random.permutation(ntrain)\n",
    "X_train = X_train[rnd_idx]\n",
    "y_train = y_train[rnd_idx]\n",
    "\n",
    "X_train_rs = X_train[:1000]\n",
    "y_train_rs = y_train[:1000]\n",
    "\n",
    "if small_dataset:\n",
    "    X_train = X_train[:number_of_instances_for_small_dataset]\n",
    "    y_train = y_train[:number_of_instances_for_small_dataset]\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255\n",
    "\n",
    "X_train_scaled_rs = X_train_rs/255\n",
    "\n",
    "print (len(X_train),len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ...C=3.5988934774124326, gamma=0.001513186272679838; total time=   0.1s\n",
      "[CV] END ...C=3.5988934774124326, gamma=0.001513186272679838; total time=   0.1s\n",
      "[CV] END ...C=3.5988934774124326, gamma=0.001513186272679838; total time=   0.0s\n",
      "[CV] END ...C=3.5988934774124326, gamma=0.001513186272679838; total time=   0.1s\n",
      "[CV] END ...C=3.5988934774124326, gamma=0.001513186272679838; total time=   0.1s\n",
      "[CV] END .....C=3.055855399572819, gamma=0.06719156480223124; total time=   0.2s\n",
      "[CV] END .....C=3.055855399572819, gamma=0.06719156480223124; total time=   0.2s\n",
      "[CV] END .....C=3.055855399572819, gamma=0.06719156480223124; total time=   0.2s\n",
      "[CV] END .....C=3.055855399572819, gamma=0.06719156480223124; total time=   0.2s\n",
      "[CV] END .....C=3.055855399572819, gamma=0.06719156480223124; total time=   0.2s\n",
      "[CV] END ....C=1.107005900704854, gamma=0.001848939794318145; total time=   0.1s\n",
      "[CV] END ....C=1.107005900704854, gamma=0.001848939794318145; total time=   0.1s\n",
      "[CV] END ....C=1.107005900704854, gamma=0.001848939794318145; total time=   0.1s\n",
      "[CV] END ....C=1.107005900704854, gamma=0.001848939794318145; total time=   0.1s\n",
      "[CV] END ....C=1.107005900704854, gamma=0.001848939794318145; total time=   0.1s\n",
      "[CV] END .....C=8.580396351217694, gamma=0.09114265653213442; total time=   0.1s\n",
      "[CV] END .....C=8.580396351217694, gamma=0.09114265653213442; total time=   0.2s\n",
      "[CV] END .....C=8.580396351217694, gamma=0.09114265653213442; total time=   0.2s\n",
      "[CV] END .....C=8.580396351217694, gamma=0.09114265653213442; total time=   0.2s\n",
      "[CV] END .....C=8.580396351217694, gamma=0.09114265653213442; total time=   0.2s\n",
      "[CV] END .....C=7.881852955024211, gamma=0.06993087682473523; total time=   0.2s\n",
      "[CV] END .....C=7.881852955024211, gamma=0.06993087682473523; total time=   0.2s\n",
      "[CV] END .....C=7.881852955024211, gamma=0.06993087682473523; total time=   0.2s\n",
      "[CV] END .....C=7.881852955024211, gamma=0.06993087682473523; total time=   0.1s\n",
      "[CV] END .....C=7.881852955024211, gamma=0.06993087682473523; total time=   0.2s\n",
      "[CV] END ....C=9.552357567109635, gamma=0.009118854871587641; total time=   0.1s\n",
      "[CV] END ....C=9.552357567109635, gamma=0.009118854871587641; total time=   0.1s\n",
      "[CV] END ....C=9.552357567109635, gamma=0.009118854871587641; total time=   0.1s\n",
      "[CV] END ....C=9.552357567109635, gamma=0.009118854871587641; total time=   0.1s\n",
      "[CV] END ....C=9.552357567109635, gamma=0.009118854871587641; total time=   0.1s\n",
      "[CV] END ....C=4.335232453578552, gamma=0.018385511949522124; total time=   0.2s\n",
      "[CV] END ....C=4.335232453578552, gamma=0.018385511949522124; total time=   0.2s\n",
      "[CV] END ....C=4.335232453578552, gamma=0.018385511949522124; total time=   0.2s\n",
      "[CV] END ....C=4.335232453578552, gamma=0.018385511949522124; total time=   0.2s\n",
      "[CV] END ....C=4.335232453578552, gamma=0.018385511949522124; total time=   0.2s\n",
      "[CV] END ...C=6.335534109540218, gamma=0.0011263118134606108; total time=   0.0s\n",
      "[CV] END ...C=6.335534109540218, gamma=0.0011263118134606108; total time=   0.1s\n",
      "[CV] END ...C=6.335534109540218, gamma=0.0011263118134606108; total time=   0.0s\n",
      "[CV] END ...C=6.335534109540218, gamma=0.0011263118134606108; total time=   0.0s\n",
      "[CV] END ...C=6.335534109540218, gamma=0.0011263118134606108; total time=   0.0s\n",
      "[CV] END ....C=10.572971700825061, gamma=0.01381957639278581; total time=   0.1s\n",
      "[CV] END ....C=10.572971700825061, gamma=0.01381957639278581; total time=   0.1s\n",
      "[CV] END ....C=10.572971700825061, gamma=0.01381957639278581; total time=   0.1s\n",
      "[CV] END ....C=10.572971700825061, gamma=0.01381957639278581; total time=   0.1s\n",
      "[CV] END ....C=10.572971700825061, gamma=0.01381957639278581; total time=   0.1s\n",
      "[CV] END ....C=9.744917916776693, gamma=0.029461872248440116; total time=   0.2s\n",
      "[CV] END ....C=9.744917916776693, gamma=0.029461872248440116; total time=   0.2s\n",
      "[CV] END ....C=9.744917916776693, gamma=0.029461872248440116; total time=   0.2s\n",
      "[CV] END ....C=9.744917916776693, gamma=0.029461872248440116; total time=   0.2s\n",
      "[CV] END ....C=9.744917916776693, gamma=0.029461872248440116; total time=   0.2s\n",
      "SVC(C=4.335232453578552, gamma=0.018385511949522124)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "### Random Search to find best 'C' and 'gamma'　\n",
    "### (This process can be skipped. These parameters are given in the next cell.\n",
    "################################ \n",
    "\n",
    "svm_clf = SVC(decision_function_shape=decision_function_shape)\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2)\n",
    "rnd_search_cv.fit(X_train_scaled_rs, y_train_rs)\n",
    "print (rnd_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### SVM Definition with given parameters (C, gamma)\n",
    "################################ \n",
    "if dataset == 1:\n",
    "    #Dataset 1 KMNNIST 10\n",
    "    C = 10.572971700825061\n",
    "    gamma = 0.01381957639278581\n",
    "elif dataset == 2:\n",
    "    #Dataset 2 K49\n",
    "    C = 4.152705171689228\n",
    "    gamma = 0.006783091541660457\n",
    "    \n",
    "svm_clf = SVC(C=C, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape=decision_function_shape, degree=3, gamma=gamma,\n",
    "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "  shrinking=True, tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting done\n",
      "accuracy on training data(not class average) 1.0\n",
      "accuracy on test data(not class average) 0.929\n"
     ]
    }
   ],
   "source": [
    "#SVM Training (fitting)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "print ('fitting done')\n",
    "with open(datadir+'Kuzushi_SVC_class_after_fitting_'+pickles_id+'.pickle', mode='wb') as f:\n",
    "    pickle.dump(svm_clf,f)\n",
    "\n",
    "#SVM Prediction for the training dataset    \n",
    "y_pred = svm_clf.predict(X_train_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_training_data_'+pickles_id+'.pickle', mode='wb') as f2:\n",
    "    pickle.dump(y_pred,f2)\n",
    "acc_train=accuracy_score(y_train, y_pred)\n",
    "print ('accuracy on training data(not class average)',acc_train)\n",
    "\n",
    "#SVM Prediction for the test dataset\n",
    "y_pred_test = svm_clf.predict(X_test_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_test_data_'+pickles_id+'.pickle', mode='wb') as f3:\n",
    "    pickle.dump(y_pred_test,f3)\n",
    "acc_test=accuracy_score(y_test, y_pred_test)\n",
    "print ('accuracy on test data(not class average)',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset==2:\n",
    "    accuracy_train = 0\n",
    "    accuracy_test = 0\n",
    "    for i in range(0,49):\n",
    "        y_index_train = np.where(y_train==i)\n",
    "        y_index_test = np.where(y_test==i)\n",
    "        acc_train=accuracy_score(y_train[y_index_train], y_pred[y_index_train])\n",
    "        acc_test=accuracy_score(y_test[y_index_test], y_pred_test[y_index_test])\n",
    "        accuracy_train+=acc_train/49\n",
    "        accuracy_test+=acc_test/49\n",
    "    print ('accuracy on training data(class averaged)',accuracy_train)\n",
    "    print ('accuracy on test data(class averaged)',accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "rforest_clf = RandomForestClassifier(n_estimators=300, criterion='gini', random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting done\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Training (fitting)\n",
    "rforest_clf.fit(X_train_scaled, y_train)\n",
    "print ('fitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data(not class average) 1.0\n",
      "accuracy on test data(not class average) 0.8623\n"
     ]
    }
   ],
   "source": [
    "with open(datadir+'Kuzushi_random_forest_class_after_fitting_'+pickles_id+'.pickle', mode='wb') as f4:\n",
    "    pickle.dump(rforest_clf,f4)\n",
    "\n",
    "#SVM Prediction for the training dataset    \n",
    "y_pred = rforest_clf.predict(X_train_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_training_data_'+pickles_id+'.pickle', mode='wb') as f5:\n",
    "    pickle.dump(y_pred,f5)\n",
    "acc_train=accuracy_score(y_train, y_pred)\n",
    "print ('accuracy on training data(not class average)',acc_train)\n",
    "\n",
    "#SVM Prediction for the test dataset\n",
    "y_pred_test = rforest_clf.predict(X_test_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_test_data_'+pickles_id+'.pickle', mode='wb') as f6:\n",
    "    pickle.dump(y_pred_test,f6)\n",
    "acc_test=accuracy_score(y_test, y_pred_test)\n",
    "print ('accuracy on test data(not class average)',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_clf = AdaBoostClassifier(n_estimators=100, learning_rate= 1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting done\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Training (fitting)\n",
    "adaboost_clf.fit(X_train_scaled, y_train)\n",
    "print ('fitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data(not class average) 0.6052\n",
      "accuracy on test data(not class average) 0.5216\n"
     ]
    }
   ],
   "source": [
    "with open(datadir+'Kuzushi_adaboost_class_after_fitting_'+pickles_id+'.pickle', mode='wb') as f7:\n",
    "    pickle.dump(adaboost_clf,f7)\n",
    "\n",
    "#SVM Prediction for the training dataset    \n",
    "y_pred = adaboost_clf.predict(X_train_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_training_data_'+pickles_id+'.pickle', mode='wb') as f8:\n",
    "    pickle.dump(y_pred,f8)\n",
    "acc_train=accuracy_score(y_train, y_pred)\n",
    "print ('accuracy on training data(not class average)',acc_train)\n",
    "\n",
    "#SVM Prediction for the test dataset\n",
    "y_pred_test = adaboost_clf.predict(X_test_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_test_data_'+pickles_id+'.pickle', mode='wb') as f9:\n",
    "    pickle.dump(y_pred_test,f9)\n",
    "acc_test=accuracy_score(y_test, y_pred_test)\n",
    "print ('accuracy on test data(not class average)',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting done\n"
     ]
    }
   ],
   "source": [
    "#Adaboost Training (fitting)\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "print ('fitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data(not class average) 0.6052\n",
      "accuracy on test data(not class average) 0.9143\n"
     ]
    }
   ],
   "source": [
    "with open(datadir+'Kuzushi_knn_class_after_fitting_'+pickles_id+'.pickle', mode='wb') as f10:\n",
    "    pickle.dump(knn_clf,f10)\n",
    "\n",
    "#SVM Prediction for the training dataset    \n",
    "y_pred = adaboost_clf.predict(X_train_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_training_data_'+pickles_id+'.pickle', mode='wb') as f11:\n",
    "    pickle.dump(y_pred,f11)\n",
    "acc_train=accuracy_score(y_train, y_pred)\n",
    "print ('accuracy on training data(not class average)',acc_train)\n",
    "\n",
    "#SVM Prediction for the test dataset\n",
    "y_pred_test = knn_clf.predict(X_test_scaled)\n",
    "with open(datadir+'Kuzushi_y_predicted_for_test_data_'+pickles_id+'.pickle', mode='wb') as f12:\n",
    "    pickle.dump(y_pred_test,f12)\n",
    "acc_test=accuracy_score(y_test, y_pred_test)\n",
    "print ('accuracy on test data(not class average)',acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
